{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Detailed comparison to Granger-causality and CCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T20:19:34.216557982Z",
     "start_time": "2023-11-01T20:19:27.683712718Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from synthetic_data import sample_points, beta, skfda_basis, spline_multi_sample\n",
    "from causal import ccm_bivariate, granger, eval_candidate_DAGs\n",
    "from kernels import K_ID\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Data\n",
    "Case 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# beta function to move from linearity to non-linearity in relationship between X and Y\n",
    "\n",
    "def beta_linear(s, t, a):\n",
    "    c_1 = np.random.uniform(0.25, 0.75)\n",
    "    c_2 = np.random.uniform(0.25, 0.75)\n",
    "    return (10 - a) + a * (8 * (s - c_1) ** 2 - 8 * (t - c_2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# historically dependent data\n",
    "def hist_data_linear(X, upper_limit, a, pred_points, s_0):\n",
    "    \"\"\"\n",
    "    Function to generate historically dependent data\n",
    "\n",
    "    Inputs:\n",
    "    X: (n_vars, n_samples * n_tests, n_obs) array of samples\n",
    "    upper_limit: upper limit for predictions\n",
    "    a: strength of dependence\n",
    "    pred_points: prediction points\n",
    "    linear: extend of linear dependence\n",
    "\n",
    "    Returns:\n",
    "    Y: (n_samples * n_tests, n_obs) response variable that is historically dependent on X\n",
    "    \"\"\"\n",
    "    if len(X.shape)==2:\n",
    "        X_arr = X.reshape(1, X.shape[0], X.shape[1])\n",
    "    else:\n",
    "        X_arr = X\n",
    "    Y = np.zeros((X_arr.shape[1], len(pred_points[pred_points <= upper_limit])))\n",
    "    s, t = np.meshgrid(pred_points[pred_points <= upper_limit], pred_points[pred_points <= upper_limit])\n",
    "    for i in range(X_arr.shape[1]):  # looping over samples\n",
    "        sum_y = np.zeros(len(pred_points[pred_points <= upper_limit]))\n",
    "        for p in range(X_arr.shape[0]):  # looping over parent variables\n",
    "            beta_p = beta_linear(s, t, a)\n",
    "            y = np.zeros(len(pred_points[pred_points <= upper_limit]))\n",
    "            for i_t, t in enumerate(pred_points[pred_points <= upper_limit]):  # looping over time points of y\n",
    "                #y[i_t] = trapezoid(X_arr[p, i][:i_t+1] * beta_p[:i_t+1, i_t])\n",
    "                if i_t >= s_0:\n",
    "                    y[i_t] = np.sum(X_arr[p, i][(i_t-s_0):i_t] * beta_p[(i_t-s_0):i_t, i_t]) / i_t\n",
    "                else:\n",
    "                    y[i_t] = 0\n",
    "\n",
    "            sum_y += y\n",
    "            Y[i] = sum_y\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Case 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# mean function to move from stationarity to non-stationity in X and Y\n",
    "\n",
    "def mean_stationary(s):\n",
    "    c_mu = np.random.normal(8, 1)\n",
    "    return np.tanh(c_mu * s - c_mu / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# historically dependent data\n",
    "def hist_data(X, upper_limit, a, pred_points, s_0):\n",
    "    \"\"\"\n",
    "    Function to generate historically dependent data\n",
    "\n",
    "    Inputs:\n",
    "    X: (n_vars, n_samples * n_tests, n_obs) array of samples\n",
    "    upper_limit: upper limit for predictions\n",
    "    a: strength of dependence\n",
    "    pred_points: prediction points\n",
    "    linear: extend of linear dependence\n",
    "\n",
    "    Returns:\n",
    "    Y: (n_samples * n_tests, n_obs) response variable that is historically dependent on X\n",
    "    \"\"\"\n",
    "    if len(X.shape)==2:\n",
    "        X_arr = X.reshape(1, X.shape[0], X.shape[1])\n",
    "    else:\n",
    "        X_arr = X\n",
    "    Y = np.zeros((X_arr.shape[1], len(pred_points[pred_points <= upper_limit])))\n",
    "    s, t = np.meshgrid(pred_points[pred_points <= upper_limit], pred_points[pred_points <= upper_limit])\n",
    "    for i in range(X_arr.shape[1]):  # looping over samples\n",
    "        sum_y = np.zeros(len(pred_points[pred_points <= upper_limit]))\n",
    "        for p in range(X_arr.shape[0]):  # looping over parent variables\n",
    "            beta_p = beta(s, t, linear=0)\n",
    "            y = np.zeros(len(pred_points[pred_points <= upper_limit]))\n",
    "            for i_t, t in enumerate(pred_points[pred_points <= upper_limit]):  # looping over time points of y\n",
    "                #y[i_t] = trapezoid(X_arr[p, i][:i_t+1] * beta_p[:i_t+1, i_t])\n",
    "                if i_t >= s_0:\n",
    "                    y[i_t] = np.sum(X_arr[p, i][(i_t-s_0):i_t] * beta_p[(i_t-s_0):i_t, i_t]) / i_t\n",
    "                else:\n",
    "                    y[i_t] = 0\n",
    "\n",
    "            sum_y += y\n",
    "            Y[i] = sum_y\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hyperparameters for data generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_trials = 200\n",
    "\n",
    "n_samples = [100, 200, 300]\n",
    "n_obs = 100\n",
    "n_preds = 100\n",
    "upper_limit = 1\n",
    "period = 0.1\n",
    "n_basis = 3\n",
    "sd = 1\n",
    "s_0 = 2\n",
    "\n",
    "a_list = [0, 2, 4, 6, 8, 10]\n",
    "\n",
    "pred_points = np.linspace(0, upper_limit, n_preds)\n",
    "alpha = 0.05\n",
    "\n",
    "n_intervals = 12\n",
    "analyse = False\n",
    "n_neighbours = 5\n",
    "n_perms = 1000\n",
    "make_K = K_ID\n",
    "regressor = 'hist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Case 1:\n",
    "Moving from linearity to non-linearity in the relationship between X and Y\n",
    "\n",
    "Analysis over 200 independent trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lens_DAGs_01_G = {}\n",
    "lens_DAGs_10_G = {}\n",
    "lens_DAGs_01_R = {}\n",
    "lens_DAGs_10_R = {}\n",
    "\n",
    "for n_sample in n_samples:\n",
    "    print('n:', n_sample)\n",
    "\n",
    "    lens_DAGs_01_G[n_sample] = {}\n",
    "    lens_DAGs_10_G[n_sample] = {}\n",
    "    lens_DAGs_01_R[n_sample] = {}\n",
    "    lens_DAGs_10_R[n_sample] = {}\n",
    "\n",
    "    for a in a_list:\n",
    "        print('a:', a)\n",
    "\n",
    "        lens_DAGs_01_G[n_sample][a] = []\n",
    "        lens_DAGs_10_G[n_sample][a] = []\n",
    "        lens_DAGs_01_R[n_sample][a] = []\n",
    "        lens_DAGs_10_R[n_sample][a] = []\n",
    "\n",
    "        for t in tqdm(range(n_trials)):\n",
    "\n",
    "            # data generation\n",
    "            obs_points_X = sample_points(n_sample, n_obs, upper_limit=upper_limit)\n",
    "            X_mat = skfda_basis(n_sample, upper_limit, period, n_basis, sd).evaluate(obs_points_X, aligned=False).squeeze()\n",
    "            X = spline_multi_sample(X_mat, obs_points_X, pred_points).evaluate(pred_points).squeeze() + np.random.normal(0, sd, size=(n_sample, n_preds))\n",
    "            Y = hist_data_linear(X, upper_limit, a, pred_points, s_0) + np.random.normal(0, sd, size=(n_sample, n_preds))\n",
    "            X_arr = np.asarray([X, Y])\n",
    "\n",
    "            DAGs = {}\n",
    "            DAGs_01_G = {}\n",
    "            DAGs_10_G = {}\n",
    "            p_values_G = {}\n",
    "            p_values_01_G = {}\n",
    "            p_values_10_G = {}\n",
    "\n",
    "            # test Granger\n",
    "            for i in range(X_arr.shape[1]):\n",
    "                DAG, _, p_value, _ = granger(X_arr[:, i, :], alpha)\n",
    "                DAGs[i] = DAG\n",
    "                p_values_G[i] = p_value\n",
    "\n",
    "                if DAG == {0: [], 1: 0}:\n",
    "                    DAGs_01_G[i] = DAG\n",
    "                    p_values_01_G[i] = p_value\n",
    "\n",
    "                if DAG == {0: 1, 1: []}:\n",
    "                    DAGs_10_G[i] = DAG\n",
    "                    p_values_10_G[i] = p_value\n",
    "\n",
    "            #print('Trial:', t)\n",
    "            #print('X causes Y:', len(DAGs_01)/len(DAGs))\n",
    "            #print('Y causes X:', len(DAGs_10)/len(DAGs))\n",
    "\n",
    "            lens_DAGs_01_G[n_sample][a].append(len(DAGs_01_G)/len(DAGs))\n",
    "            lens_DAGs_10_G[n_sample][a].append(len(DAGs_10_G)/len(DAGs))\n",
    "            \n",
    "            # test regression\n",
    "            DAG_R, p_value_R = eval_candidate_DAGs(X_arr, pred_points, n_intervals, n_neighbours, n_perms, alpha, make_K, analyse, regressor, pd_graph=None)\n",
    "            if DAG_R == {0: [], 1: [0]}:\n",
    "                lens_DAGs_01_R[n_sample][a].append(DAG_R)\n",
    "            elif DAG_R == {0: [1], 1: []}:\n",
    "                lens_DAGs_10_R[n_sample][a].append(DAG_R)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        print('Granger (X -> Y) mean for a =', a, ':', np.mean(lens_DAGs_01_G[n_sample][a]))\n",
    "        print('Granger (Y -> X) mean for a =', a, ':', np.mean(lens_DAGs_10_G[n_sample][a]))\n",
    "        \n",
    "        print('Regression (X -> Y) rate for a =', a, ':', len(lens_DAGs_01_R[n_sample][a]) / n_trials)\n",
    "        print('Regression (Y -> X) rate for a =', a, ':', len(lens_DAGs_10_R[n_sample][a]) / n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "results_01_G = open('results/causal/granger_linear_01.pkl', 'wb')\n",
    "pickle.dump(lens_DAGs_01_G, results_01_G)\n",
    "results_01_G.close()\n",
    "\n",
    "results_10_G = open('results/causal/granger_linear_10.pkl', 'wb')\n",
    "pickle.dump(lens_DAGs_10_G, results_10_G)\n",
    "results_10_G.close()\n",
    "\n",
    "results_01_R = open('results/causal/regression_linear_01_G.pkl', 'wb')\n",
    "pickle.dump(lens_DAGs_01_R, results_01_R)\n",
    "results_01_R.close()\n",
    "\n",
    "results_10_R = open('results/causal/regression_linear_10_G.pkl', 'wb')\n",
    "pickle.dump(lens_DAGs_10_R, results_10_R)\n",
    "results_10_R.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Case 2:\n",
    "Moving from stationary to non-stationary time-series samples in X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lens_DAGs_01_C = {}\n",
    "lens_DAGs_10_C = {}\n",
    "lens_DAGs_01_R = {}\n",
    "lens_DAGs_10_R = {}\n",
    "\n",
    "for n_sample in n_samples:\n",
    "    print('n:', n_sample)\n",
    "\n",
    "    lens_DAGs_01_C[n_sample] = {}\n",
    "    lens_DAGs_10_C[n_sample] = {}\n",
    "    lens_DAGs_01_R[n_sample] = {}\n",
    "    lens_DAGs_10_R[n_sample] = {}\n",
    "\n",
    "    for a in a_list:\n",
    "        print('a:', a)\n",
    "\n",
    "        lens_DAGs_01_C[n_sample][a] = []\n",
    "        lens_DAGs_10_C[n_sample][a] = []\n",
    "        lens_DAGs_01_R[n_sample][a] = []\n",
    "        lens_DAGs_10_R[n_sample][a] = []\n",
    "\n",
    "        for t in tqdm(range(n_trials)):\n",
    "\n",
    "            # data generation\n",
    "            obs_points_X = sample_points(n_sample, n_obs, upper_limit=upper_limit)\n",
    "            X_mat = a * mean_stationary(obs_points_X) + skfda_basis(n_sample, upper_limit, period, n_basis, sd).evaluate(obs_points_X, aligned=False).squeeze()\n",
    "            X = spline_multi_sample(X_mat, obs_points_X, pred_points).evaluate(pred_points).squeeze() + np.random.normal(0, sd, size=(n_sample, n_preds))\n",
    "            Y = a * mean_stationary(pred_points) + hist_data(X, upper_limit, 1, pred_points, s_0) + np.random.normal(0, sd, size=(n_sample, n_preds))\n",
    "            X_arr = np.asarray([X, Y])\n",
    "\n",
    "            DAGs = {}\n",
    "            DAGs_01_C = {}\n",
    "            DAGs_10_C = {}\n",
    "            p_values_C = {}\n",
    "            p_values_01_C = {}\n",
    "            p_values_10_C = {}\n",
    "\n",
    "            # test Granger\n",
    "            for i in range(X_arr.shape[1]):\n",
    "                DAG, _, p_value, _ = ccm_bivariate(X_arr[:, i, :], alpha)\n",
    "                DAGs[i] = DAG\n",
    "                p_values_C[i] = p_value\n",
    "\n",
    "                if DAG == {0: [], 1: 0}:\n",
    "                    DAGs_01_C[i] = DAG\n",
    "                    p_values_01_C[i] = p_value\n",
    "\n",
    "                if DAG == {0: 1, 1: []}:\n",
    "                    DAGs_10_C[i] = DAG\n",
    "                    p_values_10_C[i] = p_value\n",
    "\n",
    "            #print('Trial:', t)\n",
    "            #print('X causes Y:', len(DAGs_01)/len(DAGs))\n",
    "            #print('Y causes X:', len(DAGs_10)/len(DAGs))\n",
    "\n",
    "            lens_DAGs_01_C[n_sample][a].append(len(DAGs_01_C)/len(DAGs))\n",
    "            lens_DAGs_10_C[n_sample][a].append(len(DAGs_10_C)/len(DAGs))\n",
    "            \n",
    "            # test regression\n",
    "            DAG_R, p_value_R = eval_candidate_DAGs(X_arr, pred_points, n_intervals, n_neighbours, n_perms, alpha, make_K, analyse, regressor, pd_graph=None)\n",
    "            if DAG_R == {0: [], 1: [0]}:\n",
    "                lens_DAGs_01_R[n_sample][a].append(DAG_R)\n",
    "            elif DAG_R == {0: [1], 1: []}:\n",
    "                lens_DAGs_10_R[n_sample][a].append(DAG_R)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        print('CCM (X -> Y) mean for a =', a, ':', np.mean(lens_DAGs_01_C[n_sample][a]))\n",
    "        print('CCM (Y -> X) mean for a =', a, ':', np.mean(lens_DAGs_10_C[n_sample][a]))\n",
    "        \n",
    "        print('Regression (X -> Y) rate for a =', a, ':', len(lens_DAGs_01_R[n_sample][a]) / n_trials)\n",
    "        print('Regression (Y -> X) rate for a =', a, ':', len(lens_DAGs_10_R[n_sample][a]) / n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "results_01_C = open('results/causal/ccm_linear_01_300.pkl', 'wb')\n",
    "pickle.dump(lens_DAGs_01_C, results_01_C)\n",
    "results_01_C.close()\n",
    "\n",
    "results_10_C = open('results/causal/ccm_linear_10_300.pkl', 'wb')\n",
    "pickle.dump(lens_DAGs_10_C, results_10_C)\n",
    "results_10_C.close()\n",
    "\n",
    "results_01_R = open('results/causal/regression_linear_01_C_300.pkl', 'wb')\n",
    "pickle.dump(lens_DAGs_01_R, results_01_R)\n",
    "results_01_R.close()\n",
    "\n",
    "results_10_R = open('results/causal/regression_linear_10_C_300.pkl', 'wb')\n",
    "pickle.dump(lens_DAGs_10_R, results_10_R)\n",
    "results_10_R.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
