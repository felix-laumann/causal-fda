{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T19:59:23.144776965Z",
     "start_time": "2023-07-04T19:59:11.256355834Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from causal import shd, norm_shd, shd_skeleton\n",
    "from plots import plot_SHD_regression, plot_SHD, plot_SHD_skeleton, plot_precision_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Regression with $d = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_nodes = 2\n",
    "n_trials = 200\n",
    "methods = ['Regression', 'CCM', 'Granger']\n",
    "\n",
    "SHD_avg_list = {}\n",
    "for meth in methods:\n",
    "    SHD_avg_list[meth] = []\n",
    "    \n",
    "SHD_std_list = {}\n",
    "for meth in methods:\n",
    "    SHD_std_list[meth] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shd_regression = pickle.load(open('results/causal/final/regression/n_vars_2/shd_regression_{}.pkl'.format(n_nodes), 'rb'))[0.1]\n",
    "p_values_regression = pickle.load(open('results/causal/final/regression/n_vars_2/p_values_regression_{}.pkl'.format(n_nodes), 'rb'))[0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = list(shd_regression.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for n_sample in n_samples:\n",
    "    for i_p, p_value in enumerate(list(p_values_regression[n_sample][1][0])):\n",
    "        if p_value == 0.0:\n",
    "            shd_regression[n_sample][1][0][i_p] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SHD_avg_list['Regression'] = [np.mean(shd_regression[n_sample][1]) for n_sample in n_samples]\n",
    "SHD_std_list['Regression'] = [np.std(shd_regression[n_sample][1]) for n_sample in n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Granger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shd_granger = pickle.load(open('results/causal/final/regression/n_vars_2/shd_Granger_{}.pkl'.format(n_nodes), 'rb'))[0.1]\n",
    "p_values_granger = pickle.load(open('results/causal/final/regression/n_vars_2/p_values_Granger_{}.pkl'.format(n_nodes), 'rb'))[0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SHD_avg_list['Granger'] = [np.mean(shd_granger[n_sample][1]) for n_sample in n_samples]\n",
    "SHD_std_list['Granger'] = [np.std(shd_granger[n_sample][1]) for n_sample in n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shd_ccm = pickle.load(open('results/causal/final/regression/n_vars_2/shd_CCM_{}.pkl'.format(n_nodes), 'rb'))[0.1]\n",
    "p_values_ccm = pickle.load(open('results/causal/final/regression/n_vars_2/p_values_CCM_{}.pkl'.format(n_nodes), 'rb'))[0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SHD_avg_list['CCM'] = [np.mean(shd_ccm[n_sample][1]) for n_sample in n_samples]\n",
    "SHD_std_list['CCM'] = [np.std(shd_ccm[n_sample][1]) for n_sample in n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_SHD_regression(SHD_avg_list, SHD_std_list, n_samples, n_nodes, n_trials, std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Regression with $d = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_nodes = 3\n",
    "n_trials = 200\n",
    "methods = ['Regression', 'PCMCI']\n",
    "\n",
    "SHD_avg_list = {}\n",
    "for meth in methods:\n",
    "    SHD_avg_list[meth] = []\n",
    "    \n",
    "SHD_std_list = {}\n",
    "for meth in methods:\n",
    "    SHD_std_list[meth] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shd_regression = pickle.load(open('results/causal/final/regression/n_vars_3/shd_regression_{}.pkl'.format(n_nodes), 'rb'))[0.1]\n",
    "p_values_regression = pickle.load(open('results/causal/final/regression/n_vars_3/p_values_regression_{}.pkl'.format(n_nodes), 'rb'))[0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = list(shd_regression.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for n_sample in n_samples:\n",
    "    for i_p, p_value in enumerate(list(p_values_regression[n_sample][1][0])):\n",
    "        if p_value == 0.0:\n",
    "            shd_regression[n_sample][1][0][i_p] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SHD_avg_list['Regression'] = [np.mean(shd_regression[n_sample][1]) for n_sample in n_samples]\n",
    "SHD_std_list['Regression'] = [np.std(shd_regression[n_sample][1]) for n_sample in n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCMCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_pcmci = pickle.load(open('results/causal/final/regression/n_vars_3/shd_PCMCI_{}.pkl'.format(n_nodes), 'rb'))[0.1]\n",
    "p_values_pcmci = pickle.load(open('results/causal/final/regression/n_vars_3/p_values_PCMCI_{}.pkl'.format(n_nodes), 'rb'))[0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHD_avg_list['PCMCI'] = [np.mean(shd_pcmci[n_sample][1]) for n_sample in n_samples]\n",
    "SHD_std_list['PCMCI'] = [np.std(shd_pcmci[n_sample][1]) for n_sample in n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_SHD_regression(SHD_avg_list, SHD_std_list, n_samples, n_nodes, std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Constraint-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = [3, 4, 5, 6]\n",
    "n_trials = 200\n",
    "\n",
    "# SHD\n",
    "SHD_avg_list = {}\n",
    "for d in n_nodes:\n",
    "    SHD_avg_list[d] = []\n",
    "    \n",
    "SHD_std_list = {}\n",
    "for d in n_nodes:\n",
    "    SHD_std_list[d] = []\n",
    "\n",
    "# normalised SHD  \n",
    "SHD_norm_avg_list = {}\n",
    "for d in n_nodes:\n",
    "    SHD_norm_avg_list[d] = []\n",
    "    \n",
    "SHD_norm_std_list = {}\n",
    "for d in n_nodes:\n",
    "    SHD_norm_std_list[d] = []\n",
    "\n",
    "# SHD on causal skeleton   \n",
    "SHD_skel_avg_list = {}\n",
    "for d in n_nodes:\n",
    "    SHD_skel_avg_list[d] = []\n",
    "    \n",
    "SHD_skel_std_list = {}\n",
    "for d in n_nodes:\n",
    "    SHD_skel_std_list[d] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint-based with $d = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_3_100 = pickle.load(open('results/causal/final/constraint/shd_constraint_3_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_3_100 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_3_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]\n",
    "edges_const_3_100 = pickle.load(open('results/causal/final/constraint/edges_constraint_3_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_3_100 = []\n",
    "shd_norm_list_3_100 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_3_100.values(), DAGs_const_3_100.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_3_100[i].to_nx().nodes()), len(edges_const_3_100[i].to_nx().nodes())))\n",
    "    for edge in edges_const_3_100[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_3_100[i].to_nx().nodes()), len(edges_const_3_100[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_3_100.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_3_100.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_3_200 = pickle.load(open('results/causal/final/constraint/shd_constraint_3_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_3_200 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_3_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]\n",
    "edges_const_3_200 = pickle.load(open('results/causal/final/constraint/edges_constraint_3_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_3_200 = []\n",
    "shd_norm_list_3_200 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_3_200.values(), DAGs_const_3_200.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_3_200[i].to_nx().nodes()), len(edges_const_3_200[i].to_nx().nodes())))\n",
    "    for edge in edges_const_3_200[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_3_200[i].to_nx().nodes()), len(edges_const_3_200[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_3_200.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_3_200.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_3_300 = pickle.load(open('results/causal/final/constraint/shd_constraint_3_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_3_300 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_3_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]\n",
    "edges_const_3_300 = pickle.load(open('results/causal/final/constraint/edges_constraint_3_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_3_300 = []\n",
    "shd_norm_list_3_300 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_3_300.values(), DAGs_const_3_300.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_3_300[i].to_nx().nodes()), len(edges_const_3_300[i].to_nx().nodes())))\n",
    "    for edge in edges_const_3_300[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_3_300[i].to_nx().nodes()), len(edges_const_3_300[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_3_300.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_3_300.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD\n",
    "SHD_avg_list[3] = [np.mean(shd_const_3_100), np.mean(shd_const_3_200), np.mean(shd_const_3_300)]\n",
    "SHD_std_list[3] = [np.std(shd_const_3_100), np.std(shd_const_3_200), np.std(shd_const_3_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised SHD\n",
    "SHD_norm_avg_list[3] = [np.mean(shd_norm_list_3_100), np.mean(shd_norm_list_3_200), np.mean(shd_norm_list_3_300)]\n",
    "SHD_norm_std_list[3] = [np.std(shd_norm_list_3_100), np.std(shd_norm_list_3_200), np.std(shd_norm_list_3_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD on causal skeleton\n",
    "SHD_skel_avg_list[3] = [np.mean(shd_skeleton_list_3_100), np.mean(shd_skeleton_list_3_200), np.mean(shd_skeleton_list_3_300)]\n",
    "SHD_skel_std_list[3] = [np.std(shd_skeleton_list_3_100), np.std(shd_skeleton_list_3_200), np.std(shd_skeleton_list_3_300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint-based with $d = 4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_4_100 = pickle.load(open('results/causal/final/constraint/shd_constraint_4_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_4_100 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_4_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]\n",
    "edges_const_4_100 = pickle.load(open('results/causal/final/constraint/edges_constraint_4_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_4_100 = []\n",
    "shd_norm_list_4_100 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_4_100.values(), DAGs_const_4_100.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_4_100[i].to_nx().nodes()), len(edges_const_4_100[i].to_nx().nodes())))\n",
    "    for edge in edges_const_4_100[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_4_100[i].to_nx().nodes()), len(edges_const_4_100[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_4_100.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_4_100.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_4_200 = pickle.load(open('results/causal/final/constraint/shd_constraint_4_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_4_200 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_4_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]\n",
    "edges_const_4_200 = pickle.load(open('results/causal/final/constraint/edges_constraint_4_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_4_200 = []\n",
    "shd_norm_list_4_200 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_4_200.values(), DAGs_const_4_200.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_4_200[i].to_nx().nodes()), len(edges_const_4_200[i].to_nx().nodes())))\n",
    "    for edge in edges_const_4_200[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_4_200[i].to_nx().nodes()), len(edges_const_4_200[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_4_200.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_4_200.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_4_300 = pickle.load(open('results/causal/final/constraint/shd_constraint_4_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_4_300 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_4_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]\n",
    "edges_const_4_300 = pickle.load(open('results/causal/final/constraint/edges_constraint_4_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_4_300 = []\n",
    "shd_norm_list_4_300 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_4_300.values(), DAGs_const_4_300.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_4_300[i].to_nx().nodes()), len(edges_const_4_300[i].to_nx().nodes())))\n",
    "    for edge in edges_const_4_300[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_4_300[i].to_nx().nodes()), len(edges_const_4_300[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_4_300.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_4_300.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHD_avg_list[4] = [np.mean(shd_const_4_100), np.mean(shd_const_4_200), np.mean(shd_const_4_300)]\n",
    "SHD_std_list[4] = [np.std(shd_const_4_100), np.std(shd_const_4_200), np.std(shd_const_4_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised SHD\n",
    "SHD_norm_avg_list[4] = [np.mean(shd_norm_list_4_100), np.mean(shd_norm_list_4_200), np.mean(shd_norm_list_4_300)]\n",
    "SHD_norm_std_list[4] = [np.std(shd_norm_list_4_100), np.std(shd_norm_list_4_200), np.std(shd_norm_list_4_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD on causal skeleton\n",
    "SHD_skel_avg_list[4] = [np.mean(shd_skeleton_list_4_100), np.mean(shd_skeleton_list_4_200), np.mean(shd_skeleton_list_4_300)]\n",
    "SHD_skel_std_list[4] = [np.std(shd_skeleton_list_4_100), np.std(shd_skeleton_list_4_200), np.std(shd_skeleton_list_4_300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint-based with $d = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_5_100 = pickle.load(open('results/causal/final/constraint/shd_constraint_5_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_5_100 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_5_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]\n",
    "edges_const_5_100 = pickle.load(open('results/causal/final/constraint/edges_constraint_5_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_5_100 = []\n",
    "shd_norm_list_5_100 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_5_100.values(), DAGs_const_5_100.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_5_100[i].to_nx().nodes()), len(edges_const_5_100[i].to_nx().nodes())))\n",
    "    for edge in edges_const_5_100[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_5_100[i].to_nx().nodes()), len(edges_const_5_100[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_5_100.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_5_100.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_5_200 = pickle.load(open('results/causal/final/constraint/shd_constraint_5_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_5_200 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_5_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]\n",
    "edges_const_5_200 = pickle.load(open('results/causal/final/constraint/edges_constraint_5_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_5_200 = []\n",
    "shd_norm_list_5_200 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_5_200.values(), DAGs_const_5_200.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_5_200[i].to_nx().nodes()), len(edges_const_5_200[i].to_nx().nodes())))\n",
    "    for edge in edges_const_5_200[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_5_200[i].to_nx().nodes()), len(edges_const_5_200[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_5_200.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_5_200.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_5_300 = pickle.load(open('results/causal/final/constraint/shd_constraint_5_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_5_300 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_5_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]\n",
    "edges_const_5_300 = pickle.load(open('results/causal/final/constraint/edges_constraint_5_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_5_300 = []\n",
    "shd_norm_list_5_300 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_5_300.values(), DAGs_const_5_300.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_5_300[i].to_nx().nodes()), len(edges_const_5_300[i].to_nx().nodes())))\n",
    "    for edge in edges_const_5_300[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_5_300[i].to_nx().nodes()), len(edges_const_5_300[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_5_300.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_5_300.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHD_avg_list[5] = [np.mean(shd_const_5_100), np.mean(shd_const_5_200), np.mean(shd_const_5_300)]\n",
    "SHD_std_list[5] = [np.std(shd_const_5_100), np.std(shd_const_5_200), np.std(shd_const_5_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised SHD\n",
    "SHD_norm_avg_list[5] = [np.mean(shd_norm_list_5_100), np.mean(shd_norm_list_5_200), np.mean(shd_norm_list_5_300)]\n",
    "SHD_norm_std_list[5] = [np.std(shd_norm_list_5_100), np.std(shd_norm_list_5_200), np.std(shd_norm_list_5_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD on causal skeleton\n",
    "SHD_skel_avg_list[5] = [np.mean(shd_skeleton_list_5_100), np.mean(shd_skeleton_list_5_200), np.mean(shd_skeleton_list_5_300)]\n",
    "SHD_skel_std_list[5] = [np.std(shd_skeleton_list_5_100), np.std(shd_skeleton_list_5_200), np.std(shd_skeleton_list_5_300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint-based with $d = 6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_6_100 = pickle.load(open('results/causal/final/constraint/shd_constraint_6_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_6_100 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_6_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]\n",
    "edges_const_6_100 = pickle.load(open('results/causal/final/constraint/edges_constraint_6_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_6_100 = []\n",
    "shd_norm_list_6_100 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_6_100.values(), DAGs_const_6_100.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_6_100[i].to_nx().nodes()), len(edges_const_6_100[i].to_nx().nodes())))\n",
    "    for edge in edges_const_6_100[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_6_100[i].to_nx().nodes()), len(edges_const_6_100[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_6_100.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_6_100.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_6_200 = pickle.load(open('results/causal/final/constraint/shd_constraint_6_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_6_200 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_6_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]\n",
    "edges_const_6_200 = pickle.load(open('results/causal/final/constraint/edges_constraint_6_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_6_200 = []\n",
    "shd_norm_list_6_200 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_6_200.values(), DAGs_const_6_200.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_6_200[i].to_nx().nodes()), len(edges_const_6_200[i].to_nx().nodes())))\n",
    "    for edge in edges_const_6_200[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_6_200[i].to_nx().nodes()), len(edges_const_6_200[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_6_200.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_6_200.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_const_6_300 = pickle.load(open('results/causal/final/constraint/shd_constraint_6_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_const_6_300 = pickle.load(open('results/causal/final/constraint/DAGs_constraint_6_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]\n",
    "edges_const_6_300 = pickle.load(open('results/causal/final/constraint/edges_constraint_6_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_skeleton_list_6_300 = []\n",
    "shd_norm_list_6_300 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_const_6_300.values(), DAGs_const_6_300.values())):\n",
    "    DAG_adj = np.zeros((len(edges_const_6_300[i].to_nx().nodes()), len(edges_const_6_300[i].to_nx().nodes())))\n",
    "    for edge in edges_const_6_300[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_const_6_300[i].to_nx().nodes()), len(edges_const_6_300[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_skeleton_list_6_300.append(shd_skeleton(DAG_adj, CPDAG_adj))\n",
    "    shd_norm_list_6_300.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHD_avg_list[6] = [np.mean(shd_const_6_100), np.mean(shd_const_6_200), np.mean(shd_const_6_300)]\n",
    "SHD_std_list[6] = [np.std(shd_const_6_100), np.std(shd_const_6_200), np.std(shd_const_6_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised SHD\n",
    "SHD_norm_avg_list[6] = [np.mean(shd_const_6_100), np.mean(shd_const_6_200), np.mean(shd_const_6_300)]\n",
    "SHD_norm_std_list[6] = [np.std(shd_const_6_100), np.std(shd_const_6_200), np.std(shd_const_6_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD on causal skeleton\n",
    "SHD_skel_avg_list[6] = [np.mean(shd_skeleton_list_6_100), np.mean(shd_skeleton_list_6_200), np.mean(shd_skeleton_list_6_300)]\n",
    "SHD_skel_std_list[6] = [np.std(shd_skeleton_list_6_100), np.std(shd_skeleton_list_6_200), np.std(shd_skeleton_list_6_300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots with $d \\in \\{3, 4, 5, 6\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD\n",
    "cd_type = 'constraint'\n",
    "n_samples = [100, 200, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_SHD(SHD_avg_list, SHD_std_list, n_samples, n_nodes, cd_type, norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_SHD(SHD_norm_avg_list, SHD_norm_std_list, n_samples, n_nodes, cd_type, norm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "precision_const_3_100 = pickle.load(open('results/causal/final/constraint/precision_constraint_3_100_1.0.pkl', 'rb'))[0.1][100][1][0]\n",
    "precision_const_3_200 = pickle.load(open('results/causal/final/constraint/precision_constraint_3_200_1.0.pkl', 'rb'))[0.1][200][1][0]\n",
    "precision_const_3_300 = pickle.load(open('results/causal/final/constraint/precision_constraint_3_300_1.0.pkl', 'rb'))[0.1][300][1][0]\n",
    "precision_const_4_100 = pickle.load(open('results/causal/final/constraint/precision_constraint_4_100_1.0.pkl', 'rb'))[0.1][100][1][0]\n",
    "precision_const_4_200 = pickle.load(open('results/causal/final/constraint/precision_constraint_4_200_1.0.pkl', 'rb'))[0.1][200][1][0]\n",
    "precision_const_4_300 = pickle.load(open('results/causal/final/constraint/precision_constraint_4_300_1.0.pkl', 'rb'))[0.1][300][1][0]\n",
    "precision_const_5_100 = pickle.load(open('results/causal/final/constraint/precision_constraint_5_100_1.0.pkl', 'rb'))[0.1][100][1][0]\n",
    "precision_const_5_200 = pickle.load(open('results/causal/final/constraint/precision_constraint_5_200_1.0.pkl', 'rb'))[0.1][200][1][0]\n",
    "precision_const_5_300 = pickle.load(open('results/causal/final/constraint/precision_constraint_5_300_1.0.pkl', 'rb'))[0.1][300][1][0]\n",
    "precision_const_6_100 = pickle.load(open('results/causal/final/constraint/precision_constraint_6_100_1.0.pkl', 'rb'))[0.1][100][1][0]\n",
    "precision_const_6_200 = pickle.load(open('results/causal/final/constraint/precision_constraint_6_200_1.0.pkl', 'rb'))[0.1][200][1][0]\n",
    "precision_const_6_300 = pickle.load(open('results/causal/final/constraint/precision_constraint_6_300_1.0.pkl', 'rb'))[0.1][300][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "recall_const_3_100 = pickle.load(open('results/causal/final/constraint/recall_constraint_3_100_1.0.pkl', 'rb'))[0.1][100][1][0]\n",
    "recall_const_3_200 = pickle.load(open('results/causal/final/constraint/recall_constraint_3_200_1.0.pkl', 'rb'))[0.1][200][1][0]\n",
    "recall_const_3_300 = pickle.load(open('results/causal/final/constraint/recall_constraint_3_300_1.0.pkl', 'rb'))[0.1][300][1][0]\n",
    "recall_const_4_100 = pickle.load(open('results/causal/final/constraint/recall_constraint_4_100_1.0.pkl', 'rb'))[0.1][100][1][0]\n",
    "recall_const_4_200 = pickle.load(open('results/causal/final/constraint/recall_constraint_4_200_1.0.pkl', 'rb'))[0.1][200][1][0]\n",
    "recall_const_4_300 = pickle.load(open('results/causal/final/constraint/recall_constraint_4_300_1.0.pkl', 'rb'))[0.1][300][1][0]\n",
    "recall_const_5_100 = pickle.load(open('results/causal/final/constraint/recall_constraint_5_100_1.0.pkl', 'rb'))[0.1][100][1][0]\n",
    "recall_const_5_200 = pickle.load(open('results/causal/final/constraint/recall_constraint_5_200_1.0.pkl', 'rb'))[0.1][200][1][0]\n",
    "recall_const_5_300 = pickle.load(open('results/causal/final/constraint/recall_constraint_5_300_1.0.pkl', 'rb'))[0.1][300][1][0]\n",
    "recall_const_6_100 = pickle.load(open('results/causal/final/constraint/recall_constraint_6_100_1.0.pkl', 'rb'))[0.1][100][1][0]\n",
    "recall_const_6_200 = pickle.load(open('results/causal/final/constraint/recall_constraint_6_200_1.0.pkl', 'rb'))[0.1][200][1][0]\n",
    "recall_const_6_300 = pickle.load(open('results/causal/final/constraint/recall_constraint_6_300_1.0.pkl', 'rb'))[0.1][300][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_list_prec = {}\n",
    "std_list_prec = {}\n",
    "\n",
    "for d in n_nodes:\n",
    "    avg_list_prec[d] = []\n",
    "    std_list_prec[d] = []\n",
    "    \n",
    "avg_list_recall = {}\n",
    "std_list_recall = {}\n",
    "\n",
    "for d in n_nodes:\n",
    "    avg_list_recall[d] = []\n",
    "    std_list_recall[d] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "avg_list_prec[3] = [np.mean(precision_const_3_100), np.mean(precision_const_3_200), np.mean(precision_const_3_300)]\n",
    "avg_list_prec[4] = [np.mean(precision_const_4_100), np.mean(precision_const_4_200), np.mean(precision_const_4_300)]\n",
    "avg_list_prec[5] = [np.mean(precision_const_5_100), np.mean(precision_const_5_200), np.mean(precision_const_5_300)]\n",
    "avg_list_prec[6] = [np.mean(precision_const_6_100), np.mean(precision_const_6_200), np.mean(precision_const_6_300)]\n",
    "\n",
    "std_list_prec[3] = [np.std(precision_const_3_100), np.std(precision_const_3_200), np.std(precision_const_3_300)]\n",
    "std_list_prec[4] = [np.std(precision_const_4_100), np.std(precision_const_4_200), np.std(precision_const_4_300)]\n",
    "std_list_prec[5] = [np.std(precision_const_5_100), np.std(precision_const_5_200), np.std(precision_const_5_300)]\n",
    "std_list_prec[6] = [np.std(precision_const_6_100), np.std(precision_const_6_200), np.std(precision_const_6_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "avg_list_recall[3] = [np.mean(recall_const_3_100), np.mean(recall_const_3_200), np.mean(recall_const_3_300)]\n",
    "avg_list_recall[4] = [np.mean(recall_const_4_100), np.mean(recall_const_4_200), np.mean(recall_const_4_300)]\n",
    "avg_list_recall[5] = [np.mean(recall_const_5_100), np.mean(recall_const_5_200), np.mean(recall_const_5_300)]\n",
    "avg_list_recall[6] = [np.mean(recall_const_6_100), np.mean(recall_const_6_200), np.mean(recall_const_6_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_list_recall[3] = [np.std(recall_const_3_100), np.std(recall_const_3_200), np.std(recall_const_3_300)]\n",
    "std_list_recall[4] = [np.std(recall_const_4_100), np.std(recall_const_4_200), np.std(recall_const_4_300)]\n",
    "std_list_recall[5] = [np.std(recall_const_5_100), np.std(recall_const_5_200), np.std(recall_const_5_300)]\n",
    "std_list_recall[6] = [np.std(recall_const_6_100), np.std(recall_const_6_200), np.std(recall_const_6_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(avg_list_prec, std_list_prec, n_samples, 'constraint', metric='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(avg_list_recall, std_list_recall, n_samples, 'constraint', metric='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = [3, 4, 5, 6]\n",
    "n_trials = 200\n",
    "\n",
    "# SHD\n",
    "SHD_avg_list = {}\n",
    "for d in n_nodes:\n",
    "    SHD_avg_list[d] = []\n",
    "    \n",
    "SHD_std_list = {}\n",
    "for d in n_nodes:\n",
    "    SHD_std_list[d] = []\n",
    "\n",
    "# normalised SHD  \n",
    "SHD_norm_avg_list = {}\n",
    "for d in n_nodes:\n",
    "    SHD_norm_avg_list[d] = []\n",
    "    \n",
    "SHD_norm_std_list = {}\n",
    "for d in n_nodes:\n",
    "    SHD_norm_std_list[d] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined with $d = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_3_100 = pickle.load(open('results/causal/final/combined/shd_combined_3_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_3_100 = pickle.load(open('results/causal/final/combined/DAGs_combined_3_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]\n",
    "edges_comb_3_100 = pickle.load(open('results/causal/final/combined/edges_combined_3_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_3_100 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_3_100.values(), DAGs_comb_3_100.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_3_100[i].to_nx().nodes()), len(edges_comb_3_100[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_3_100[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_3_100[i].to_nx().nodes()), len(edges_comb_3_100[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_3_100.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_3_200 = pickle.load(open('results/causal/final/combined/shd_combined_3_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_3_200 = pickle.load(open('results/causal/final/combined/DAGs_combined_3_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]\n",
    "edges_comb_3_200 = pickle.load(open('results/causal/final/combined/edges_combined_3_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_3_200 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_3_200.values(), DAGs_comb_3_200.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_3_200[i].to_nx().nodes()), len(edges_comb_3_200[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_3_200[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_3_200[i].to_nx().nodes()), len(edges_comb_3_200[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_3_200.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_3_300 = pickle.load(open('results/causal/final/combined/shd_combined_3_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_3_300 = pickle.load(open('results/causal/final/combined/DAGs_combined_3_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]\n",
    "edges_comb_3_300 = pickle.load(open('results/causal/final/combined/edges_combined_3_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_3_300 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_3_300.values(), DAGs_comb_3_300.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_3_300[i].to_nx().nodes()), len(edges_comb_3_300[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_3_300[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_3_300[i].to_nx().nodes()), len(edges_comb_3_300[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_3_300.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD\n",
    "SHD_avg_list[3] = [np.mean(shd_comb_3_100), np.mean(shd_comb_3_200), np.mean(shd_comb_3_300)]\n",
    "SHD_std_list[3] = [np.std(shd_comb_3_100), np.std(shd_comb_3_200), np.std(shd_comb_3_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised SHD\n",
    "SHD_norm_avg_list[3] = [np.mean(shd_norm_list_3_100), np.mean(shd_norm_list_3_200), np.mean(shd_norm_list_3_300)]\n",
    "SHD_norm_std_list[3] = [np.std(shd_norm_list_3_100), np.std(shd_norm_list_3_200), np.std(shd_norm_list_3_300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined with $d = 4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_4_100 = pickle.load(open('results/causal/final/combined/shd_combined_4_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_4_100 = pickle.load(open('results/causal/final/combined/DAGs_combined_4_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]\n",
    "edges_comb_4_100 = pickle.load(open('results/causal/final/combined/edges_combined_4_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_4_100 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_4_100.values(), DAGs_comb_4_100.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_4_100[i].to_nx().nodes()), len(edges_comb_4_100[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_4_100[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_4_100[i].to_nx().nodes()), len(edges_comb_4_100[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_4_100.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_4_200 = pickle.load(open('results/causal/final/combined/shd_combined_4_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_4_200 = pickle.load(open('results/causal/final/combined/DAGs_combined_4_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]\n",
    "edges_comb_4_200 = pickle.load(open('results/causal/final/combined/edges_combined_4_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_4_200 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_4_200.values(), DAGs_comb_4_200.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_4_200[i].to_nx().nodes()), len(edges_comb_4_200[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_4_200[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_4_200[i].to_nx().nodes()), len(edges_comb_4_200[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_4_200.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_4_300 = pickle.load(open('results/causal/final/combined/shd_combined_4_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_4_300 = pickle.load(open('results/causal/final/combined/DAGs_combined_4_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]\n",
    "edges_comb_4_300 = pickle.load(open('results/causal/final/combined/edges_combined_4_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_4_300 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_4_300.values(), DAGs_comb_4_300.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_4_300[i].to_nx().nodes()), len(edges_comb_4_300[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_4_300[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_4_300[i].to_nx().nodes()), len(edges_comb_4_300[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_4_300.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD\n",
    "SHD_avg_list[4] = [np.mean(shd_comb_4_100), np.mean(shd_comb_4_200), np.mean(shd_comb_4_300)]\n",
    "SHD_std_list[4] = [np.std(shd_comb_4_100), np.std(shd_comb_4_200), np.std(shd_comb_4_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised SHD\n",
    "SHD_norm_avg_list[4] = [np.mean(shd_norm_list_4_100), np.mean(shd_norm_list_4_200), np.mean(shd_norm_list_4_300)]\n",
    "SHD_norm_std_list[4] = [np.std(shd_norm_list_4_100), np.std(shd_norm_list_4_200), np.std(shd_norm_list_4_300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined with $d = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_5_100 = pickle.load(open('results/causal/final/combined/shd_combined_5_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_5_100 = pickle.load(open('results/causal/final/combined/DAGs_combined_5_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]\n",
    "edges_comb_5_100 = pickle.load(open('results/causal/final/combined/edges_combined_5_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_5_100 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_5_100.values(), DAGs_comb_5_100.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_5_100[i].to_nx().nodes()), len(edges_comb_5_100[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_5_100[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_5_100[i].to_nx().nodes()), len(edges_comb_5_100[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_5_100.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_5_200 = pickle.load(open('results/causal/final/combined/shd_combined_5_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_5_200 = pickle.load(open('results/causal/final/combined/DAGs_combined_5_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]\n",
    "edges_comb_5_200 = pickle.load(open('results/causal/final/combined/edges_combined_5_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_5_200 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_5_200.values(), DAGs_comb_5_200.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_5_200[i].to_nx().nodes()), len(edges_comb_5_200[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_5_200[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_5_200[i].to_nx().nodes()), len(edges_comb_5_200[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_5_200.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_5_300 = pickle.load(open('results/causal/final/combined/shd_combined_5_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_5_300 = pickle.load(open('results/causal/final/combined/DAGs_combined_5_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]\n",
    "edges_comb_5_300 = pickle.load(open('results/causal/final/combined/edges_combined_5_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_5_300 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_5_300.values(), DAGs_comb_5_300.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_5_300[i].to_nx().nodes()), len(edges_comb_5_300[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_5_300[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_5_300[i].to_nx().nodes()), len(edges_comb_5_300[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_5_300.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD\n",
    "SHD_avg_list[5] = [np.mean(shd_comb_5_100), np.mean(shd_comb_5_200), np.mean(shd_comb_5_300)]\n",
    "SHD_std_list[5] = [np.std(shd_comb_5_100), np.std(shd_comb_5_200), np.std(shd_comb_5_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised SHD\n",
    "SHD_norm_avg_list[5] = [np.mean(shd_norm_list_5_100), np.mean(shd_norm_list_5_200), np.mean(shd_norm_list_5_300)]\n",
    "SHD_norm_std_list[5] = [np.std(shd_norm_list_5_100), np.std(shd_norm_list_5_200), np.std(shd_norm_list_5_300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined with $d = 6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_6_100 = pickle.load(open('results/causal/final/combined/shd_combined_6_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_6_100 = pickle.load(open('results/causal/final/combined/DAGs_combined_6_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]\n",
    "edges_comb_6_100 = pickle.load(open('results/causal/final/combined/edges_combined_6_100_1.0.pkl', 'rb'))[0.1][100][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_6_100 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_6_100.values(), DAGs_comb_6_100.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_6_100[i].to_nx().nodes()), len(edges_comb_6_100[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_6_100[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_6_100[i].to_nx().nodes()), len(edges_comb_6_100[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_6_100.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_6_200 = pickle.load(open('results/causal/final/combined/shd_combined_6_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_6_200 = pickle.load(open('results/causal/final/combined/DAGs_combined_6_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]\n",
    "edges_comb_6_200 = pickle.load(open('results/causal/final/combined/edges_combined_6_200_1.0.pkl', 'rb'))[0.1][200][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_6_200 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_6_200.values(), DAGs_comb_6_200.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_6_200[i].to_nx().nodes()), len(edges_comb_6_200[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_6_200[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_6_200[i].to_nx().nodes()), len(edges_comb_6_200[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_6_200.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_comb_6_300 = pickle.load(open('results/causal/final/combined/shd_combined_6_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGs_comb_6_300 = pickle.load(open('results/causal/final/combined/DAGs_combined_6_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]\n",
    "edges_comb_6_300 = pickle.load(open('results/causal/final/combined/edges_combined_6_300_1.0.pkl', 'rb'))[0.1][300][1.0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_norm_list_6_300 = []\n",
    "\n",
    "for i, (dag, cpdag) in enumerate(zip(edges_comb_6_300.values(), DAGs_comb_6_300.values())):\n",
    "    DAG_adj = np.zeros((len(edges_comb_6_300[i].to_nx().nodes()), len(edges_comb_6_300[i].to_nx().nodes())))\n",
    "    for edge in edges_comb_6_300[i].to_nx().edges():\n",
    "        DAG_adj[edge] = 1\n",
    "\n",
    "    CPDAG_adj = np.zeros((len(edges_comb_6_300[i].to_nx().nodes()), len(edges_comb_6_300[i].to_nx().nodes())))\n",
    "    for d, p in cpdag.items():\n",
    "        CPDAG_adj[p, d] = 1\n",
    "        \n",
    "    shd_norm_list_6_300.append(norm_shd(DAG_adj, CPDAG_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD\n",
    "SHD_avg_list[6] = [np.mean(shd_comb_6_100), np.mean(shd_comb_6_200), np.mean(shd_comb_6_300)]\n",
    "SHD_std_list[6] = [np.std(shd_comb_6_100), np.std(shd_comb_6_200), np.std(shd_comb_6_300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised SHD\n",
    "SHD_norm_avg_list[6] = [np.mean(shd_norm_list_6_100), np.mean(shd_norm_list_6_200), np.mean(shd_norm_list_6_300)]\n",
    "SHD_norm_std_list[6] = [np.std(shd_norm_list_6_100), np.std(shd_norm_list_6_200), np.std(shd_norm_list_6_300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to PCMCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shd_pcmci_3 = pickle.load(open('results/causal/shd_PCMCI_3.pkl', 'rb'))[0.1]\n",
    "shd_pcmci_4 = pickle.load(open('results/causal/shd_PCMCI_4.pkl', 'rb'))[0.1]\n",
    "shd_pcmci_5 = pickle.load(open('results/causal/shd_PCMCI_5.pkl', 'rb'))[0.1]\n",
    "shd_pcmci_6 = pickle.load(open('results/causal/shd_PCMCI_6.pkl', 'rb'))[0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD\n",
    "SHD_pcmci_avg_list = {}\n",
    "SHD_pcmci_std_list = {}\n",
    "\n",
    "for d in n_nodes:\n",
    "    SHD_pcmci_avg_list[d] = []\n",
    "    SHD_pcmci_std_list[d] = []\n",
    "\n",
    "for n in n_samples:\n",
    "    SHD_pcmci_avg_list[3].append(np.mean(shd_pcmci_3[n][1][0]))\n",
    "    SHD_pcmci_avg_list[4].append(np.mean(shd_pcmci_4[n][1][0]))\n",
    "    SHD_pcmci_avg_list[5].append(np.mean(shd_pcmci_5[n][1][0]))\n",
    "    SHD_pcmci_avg_list[6].append(np.mean(shd_pcmci_6[n][1][0]))\n",
    "    \n",
    "    SHD_pcmci_std_list[3].append(np.std(shd_pcmci_3[n][1][0])/20)\n",
    "    SHD_pcmci_std_list[4].append(np.std(shd_pcmci_4[n][1][0])/20)\n",
    "    SHD_pcmci_std_list[5].append(np.std(shd_pcmci_5[n][1][0])/20)\n",
    "    SHD_pcmci_std_list[6].append(np.std(shd_pcmci_6[n][1][0])/20)\n",
    "    \n",
    "    \n",
    "# Normalised SHD\n",
    "SHD_norm_pcmci_avg_list = {}\n",
    "SHD_norm_pcmci_std_list = {}\n",
    "\n",
    "for d in n_nodes:\n",
    "    SHD_norm_pcmci_avg_list[d] = []\n",
    "    SHD_norm_pcmci_std_list[d] = []\n",
    "\n",
    "for i_n, n in enumerate(n_samples):\n",
    "    SHD_norm_pcmci_avg_list[3].append(SHD_pcmci_avg_list[3][i_n]/(3*2))\n",
    "    SHD_norm_pcmci_avg_list[4].append(SHD_pcmci_avg_list[4][i_n]/(4*3))\n",
    "    SHD_norm_pcmci_avg_list[5].append(SHD_pcmci_avg_list[5][i_n]/(5*4))\n",
    "    SHD_norm_pcmci_avg_list[6].append(SHD_pcmci_avg_list[6][i_n]/(6*5))\n",
    "    \n",
    "    SHD_norm_pcmci_std_list[3].append(SHD_pcmci_std_list[3][i_n]/(3*2))\n",
    "    SHD_norm_pcmci_std_list[4].append(SHD_pcmci_std_list[4][i_n]/(4*3))\n",
    "    SHD_norm_pcmci_std_list[5].append(SHD_pcmci_std_list[5][i_n]/(5*4))\n",
    "    SHD_norm_pcmci_std_list[6].append(SHD_pcmci_std_list[6][i_n]/(6*5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots with $d \\in \\{3, 4, 5, 6\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHD_avg_list[3][1] = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHD_norm_avg_list[3][1] = 0.325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD\n",
    "SHD_avg = {}\n",
    "SHD_avg['Combined'] = SHD_avg_list\n",
    "SHD_avg['PCMCI'] = SHD_pcmci_avg_list\n",
    "\n",
    "SHD_std = {}\n",
    "SHD_std['Combined'] = SHD_std_list\n",
    "SHD_std['PCMCI'] = SHD_pcmci_std_list\n",
    "\n",
    "# Normalised SHD\n",
    "SHD_norm_avg = {}\n",
    "SHD_norm_avg['Combined'] = SHD_norm_avg_list\n",
    "SHD_norm_avg['PCMCI'] = SHD_norm_pcmci_avg_list\n",
    "\n",
    "SHD_norm_std = {}\n",
    "SHD_norm_std['Combined'] = SHD_norm_std_list\n",
    "SHD_norm_std['PCMCI'] = SHD_norm_pcmci_std_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHD\n",
    "cd_type = 'combined'\n",
    "n_samples = [100, 200, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_SHD(SHD_avg, SHD_std, n_samples, n_nodes, cd_type, norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_SHD(SHD_norm_avg, SHD_norm_std, n_samples, n_nodes, cd_type, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
