{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Detailed comparison to Granger-causality and CCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T20:37:27.460825076Z",
     "start_time": "2023-11-08T20:37:27.435687852Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from synthetic_data import sample_points, beta, skfda_basis, spline_multi_sample\n",
    "from causal import ccm_bivariate, granger, eval_candidate_DAGs, shd\n",
    "from kernels import K_ID\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Data\n",
    "Case 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# mean function to move from stationarity to non-stationity in X and Y\n",
    "\n",
    "def mean_stationary(s):\n",
    "    c_nu = np.random.normal(8, 1)\n",
    "    return np.tanh(c_nu * s - c_nu / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def two_log(X0, Y0, r_x, r_y, B_xy, B_yx, n_samples, n_preds):\n",
    "    \"\"\"\n",
    "    Function to generate data according to a coupled two-species nonlinear logistic difference system with chaotic dynamics\n",
    "    Inputs:\n",
    "    X0: initial value for X\n",
    "    Y0: initial value for Y\n",
    "    r_x: system parameter (set between 3 and 4)\n",
    "    r_y: system parameter (set between 3 and 4)\n",
    "    B_xy: effect of Y on X\n",
    "    B_yx: effect of X on Y\n",
    "\n",
    "    Returns:\n",
    "    X_fd_list\n",
    "    \"\"\"\n",
    "    X_fd_list = np.empty((2, n_samples, n_preds))\n",
    "    t = n_preds * n_samples * 2\n",
    "\n",
    "    X = [X0]\n",
    "    Y = [Y0]\n",
    "    for i_t in range(t-1):\n",
    "        X_ = X[-1] * (r_x - r_x * X[-1] - B_xy * Y[-1])\n",
    "        Y_ = Y[-1] * (r_y - r_y * Y[-1] - B_yx * X[-1])\n",
    "        X.append(X_)\n",
    "        Y.append(Y_)\n",
    "\n",
    "    for n_s in range(n_samples):\n",
    "        X_fd_list[0, n_s] = np.asarray(X)[(2*n_s) * n_preds:((2*n_s) + 1) * n_preds]\n",
    "        X_fd_list[1, n_s] = np.asarray(Y)[(2*n_s) * n_preds:((2*n_s) + 1) * n_preds]\n",
    "\n",
    "    return X_fd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historically dependent data\n",
    "def hist_data_linear(X, upper_limit, r, pred_points):\n",
    "    \"\"\"\n",
    "    Function to generate historically dependent data\n",
    "\n",
    "    Inputs:\n",
    "    X: (n_vars, n_samples * n_tests, n_obs) array of samples\n",
    "    upper_limit: upper limit for predictions\n",
    "    r: strength of dependence\n",
    "    pred_points: prediction points\n",
    "    linear: extend of linear dependence\n",
    "\n",
    "    Returns:\n",
    "    Y: (n_samples * n_tests, n_obs) response variable that is historically dependent on X\n",
    "    \"\"\"\n",
    "    if len(X.shape)==2:\n",
    "        X_arr = X.reshape(1, X.shape[0], X.shape[1])\n",
    "    else:\n",
    "        X_arr = X\n",
    "    Y = np.zeros((X_arr.shape[1], len(pred_points[pred_points <= upper_limit])))\n",
    "    s, t = np.meshgrid(pred_points[pred_points <= upper_limit], pred_points[pred_points <= upper_limit])\n",
    "    for i in range(X_arr.shape[1]):  # looping over samples\n",
    "        sum_y = np.zeros(len(pred_points[pred_points <= upper_limit]))\n",
    "        for p in range(X_arr.shape[0]):  # looping over parent variables\n",
    "            y = np.zeros(len(pred_points[pred_points <= upper_limit]))\n",
    "            for i_t, t in enumerate(pred_points[pred_points <= upper_limit]):  # looping over time points of y\n",
    "                if i_t > 0:\n",
    "                    y[i_t] = np.sum(X_arr[p, i][:i_t + 1]) / i_t\n",
    "                else:\n",
    "                    y[i_t] = np.sum(X_arr[p, i][:i_t + 1])\n",
    "\n",
    "            sum_y += y\n",
    "            Y[i] = sum_y\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hyperparameters for data generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_trials = 200\n",
    "\n",
    "n_samples = [100]\n",
    "n_obs = 100\n",
    "n_preds = 100\n",
    "upper_limit = 1\n",
    "period = 0.1\n",
    "n_basis = 3\n",
    "sd = 1\n",
    "\n",
    "r_list = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "pred_points = np.linspace(0, upper_limit, n_preds)\n",
    "alpha = 0.05\n",
    "\n",
    "n_intervals = 12\n",
    "analyse = False\n",
    "n_neighbours = 5\n",
    "n_perms = 1000\n",
    "make_K = K_ID\n",
    "regressor = 'hist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Case 1:\n",
    "Moving from linearity to non-linearity in the relationship between X and Y\n",
    "\n",
    "Analysis over 200 independent trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SHDs_dict_G = {}\n",
    "SHDs_dict_R = {}\n",
    "\n",
    "for n_sample in n_samples:\n",
    "    print('n:', n_sample)\n",
    "\n",
    "    SHDs_dict_G[n_sample] = {}\n",
    "    SHDs_dict_R[n_sample] = {}\n",
    "\n",
    "    for r in r_list:\n",
    "        print('r:', r)\n",
    "\n",
    "        SHDs_dict_G[n_sample][r] = []\n",
    "        SHDs_dict_R[n_sample][r] = []\n",
    "\n",
    "        for t in tqdm(range(n_trials)):\n",
    "\n",
    "            # data generation\n",
    "            true_DAG = np.array([[0, 1], [0, 0]])\n",
    "            obs_points_X = sample_points(n_sample, n_obs, upper_limit=upper_limit)\n",
    "            X_mat = skfda_basis(n_sample, upper_limit, period, n_basis, sd).evaluate(obs_points_X, aligned=False).squeeze()\n",
    "            X = spline_multi_sample(X_mat, obs_points_X, pred_points).evaluate(pred_points).squeeze() + np.random.normal(0, sd, size=(n_sample, n_preds))\n",
    "            Y = (1 - r) * X + r * hist_data(X, upper_limit, r, pred_points) + np.random.normal(0, sd, size=(n_sample, n_preds))\n",
    "            Y = (1 - r) * hist_data_linear(X, upper_limit, r, pred_points) + r * hist_data(X, upper_limit, r, pred_points) + np.random.normal(0, sd, size=(n_sample, n_preds))\n",
    "            X_arr = np.asarray([X, Y])\n",
    "\n",
    "            # test Granger\n",
    "            for i in range(X_arr.shape[1]):\n",
    "                DAG, _, p_value, _ = granger(X_arr[:, i, :], alpha)\n",
    "            \n",
    "            DAG_adj = np.zeros((len(true_DAG), len(true_DAG)))\n",
    "            for d, p in DAG.items():\n",
    "                DAG_adj[p, d] = 1\n",
    "            SHDs_dict_G[n_sample][r].append(shd(true_DAG, DAG_adj))\n",
    "            \n",
    "            # test regression\n",
    "            DAG_R, p_value_R = eval_candidate_DAGs(X_arr, pred_points, n_intervals, n_neighbours, n_perms, alpha, make_K, analyse, regressor, pd_graph=None)\n",
    "            \n",
    "            DAG_R_adj = np.zeros((len(true_DAG), len(true_DAG)))\n",
    "            for d, p in DAG_R.items():\n",
    "                DAG_R_adj[p, d] = 1\n",
    "            SHDs_dict_R[n_sample][r].append(shd(true_DAG, DAG_R_adj))\n",
    "            \n",
    "        print('Granger (X -> Y) SHD for r =', r, ':', np.mean(SHDs_dict_G[n_sample][r]))\n",
    "        print('Regression (X -> Y) SHD for r =', r, ':', np.mean(SHDs_dict_R[n_sample][r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "results_SHD_G = open('results/causal/granger_linear_01_SHD_1.pkl', 'wb')\n",
    "pickle.dump(SHDs_dict_G, results_SHD_G)\n",
    "results_SHD_G.close()\n",
    "\n",
    "results_SHD_R = open('results/causal/regression_linear_01_G_SHD_1.pkl', 'wb')\n",
    "pickle.dump(SHDs_dict_R, results_SHD_R)\n",
    "results_SHD_R.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Case 2:\n",
    "Moving from stationary to non-stationary time-series samples in X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SHDs_dict_C = {}\n",
    "SHDs_dict_R = {}\n",
    "\n",
    "for n_sample in n_samples:\n",
    "    print('n:', n_sample)\n",
    "    SHDs_dict_C[n_sample] = {}\n",
    "    SHDs_dict_R[n_sample] = {}\n",
    "    \n",
    "    for r in r_list:\n",
    "        print('r:', r)\n",
    "        SHDs_dict_C[n_sample][r] = []\n",
    "        SHDs_dict_R[n_sample][r] = []\n",
    "\n",
    "        for t in tqdm(range(n_trials)):\n",
    "\n",
    "            # data generation\n",
    "            true_DAG = np.array([[0, 1], [0, 0]])\n",
    "            obs_points_X = sample_points(n_sample, n_obs, upper_limit=upper_limit)\n",
    "            XY = two_log(0.8, 0.2, 3.8, 3.2, 0.02, 0.1, n_sample, n_preds)\n",
    "            X = XY[0] + r * mean_stationary(pred_points)\n",
    "            Y = XY[1] + r * mean_stationary(pred_points)\n",
    "            X_arr = np.asarray([X, Y])\n",
    "\n",
    "            # test Granger\n",
    "            for i in range(X_arr.shape[1]):\n",
    "                DAG, _, p_value, _ = ccm_bivariate(X_arr[:, i, :], alpha)\n",
    "            \n",
    "            DAG_adj = np.zeros((len(true_DAG), len(true_DAG)))\n",
    "            for d, p in DAG.items():\n",
    "                DAG_adj[p, d] = 1\n",
    "            SHDs_dict_C[n_sample][r].append(shd(true_DAG, DAG_adj))\n",
    "            \n",
    "            # test regression\n",
    "            DAG_R, p_value_R = eval_candidate_DAGs(X_arr, pred_points, n_intervals, n_neighbours, n_perms, alpha, make_K, analyse, regressor, pd_graph=None)\n",
    "\n",
    "            DAG_R_adj = np.zeros((len(true_DAG), len(true_DAG)))\n",
    "            for d, p in DAG_R.items():\n",
    "                DAG_R_adj[p, d] = 1\n",
    "            SHDs_dict_R[n_sample][r].append(shd(true_DAG, DAG_R_adj))\n",
    "            \n",
    "        print('CCM (X -> Y) SHD for r =', r, ':', np.mean(SHDs_dict_C[n_sample][r]))\n",
    "        print('Regression (X -> Y) SHD for r =', r, ':', np.mean(SHDs_dict_R[n_sample][r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "results_SHD_C = open('results/causal/ccm_linear_01_SHD.pkl', 'wb')\n",
    "pickle.dump(SHDs_dict_C, results_SHD_C)\n",
    "results_SHD_C.close()\n",
    "\n",
    "results_SHD_R = open('results/causal/regression_linear_01_C_SHD.pkl', 'wb')\n",
    "pickle.dump(SHDs_dict_R, results_SHD_R)\n",
    "results_SHD_R.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
