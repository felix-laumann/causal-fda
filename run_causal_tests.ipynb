{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Analysis of causal discovery algorithm on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T07:45:15.164398681Z",
     "start_time": "2023-05-09T07:45:09.069024711Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from synthetic_data import generate_data\n",
    "from causal import causal_eval\n",
    "from plots import plot_SHD, plot_samples\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# number of trials and permutations\n",
    "n_trials = 1\n",
    "n_perms = 1000\n",
    "\n",
    "# number of samples and number of points functional data samples are (randomly) observed and discretised\n",
    "n_samples = [100]\n",
    "n_obs = 100\n",
    "n_preds = 100\n",
    "\n",
    "# define discretised mesh of points\n",
    "upper_limit = 1\n",
    "pred_points = np.linspace(0, upper_limit, n_preds)\n",
    "\n",
    "# data paramterers\n",
    "periods = [0.1]\n",
    "n_basis = 3\n",
    "sd = 1\n",
    "\n",
    "# statistical significance level\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create folders to save results\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "\n",
    "if not os.path.exists('results/causal'):\n",
    "    os.mkdir('results/causal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Parameters specific for evaluation on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test = 'joint'\n",
    "n_vars = 3\n",
    "prob = 0.5\n",
    "cd_type = 'constraint'\n",
    "\n",
    "# historical dependence is easier to detect the higher a is\n",
    "a_list = [1]\n",
    "\n",
    "# regression parameters\n",
    "n_intervals = 12\n",
    "analyse = True\n",
    "\n",
    "# constraint parameters\n",
    "lambs = [1e-5, 1e-4, 1e-3]\n",
    "#lambs = 2.5e-4\n",
    "n_steps = 50\n",
    "n_pretests = 100\n",
    "\n",
    "log_sys = False\n",
    "\n",
    "linear = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# saving evaluation metrics\n",
    "precisions_dict = {}\n",
    "recalls_dict = {}\n",
    "f1_scores_dict = {}\n",
    "SHDs_dict = {}\n",
    "GLs_dict = {}\n",
    "averages_dict = {}\n",
    "\n",
    "# saving DAGs + p-values\n",
    "edges_dict = {}\n",
    "DAGs_dict = {}\n",
    "p_values_dict = {}\n",
    "\n",
    "for p in periods:\n",
    "    print('Period T:', p)\n",
    "    precisions_dict[p] = {}\n",
    "    recalls_dict[p] = {}\n",
    "    f1_scores_dict[p] = {}\n",
    "    SHDs_dict[p] = {}\n",
    "    GLs_dict[p] = {}\n",
    "    averages_dict[p] = {}\n",
    "    edges_dict[p] = {}\n",
    "    DAGs_dict[p] = {}\n",
    "    p_values_dict[p] = {}\n",
    "    \n",
    "    for n_sample in tqdm(n_samples):\n",
    "        print('Sample size:', n_sample)\n",
    "\n",
    "        precisions_dict[p][n_sample] = {}\n",
    "        recalls_dict[p][n_sample] = {}\n",
    "        f1_scores_dict[p][n_sample] = {}\n",
    "        SHDs_dict[p][n_sample] = {}\n",
    "        GLs_dict[p][n_sample] = {}\n",
    "        averages_dict[p][n_sample] = {}\n",
    "        edges_dict[p][n_sample] = {}\n",
    "        DAGs_dict[p][n_sample] = {}\n",
    "        p_values_dict[p][n_sample] = {}\n",
    "\n",
    "        for i, a in enumerate(a_list):\n",
    "            print('a:', a)\n",
    "\n",
    "            precisions_dict[p][n_sample][a] = []\n",
    "            recalls_dict[p][n_sample][a] = []\n",
    "            f1_scores_dict[p][n_sample][a] = []\n",
    "            SHDs_dict[p][n_sample][a] = []\n",
    "            GLs_dict[p][n_sample][a] = []\n",
    "            averages_dict[p][n_sample][a] = []\n",
    "            edges_dict[p][n_sample][a] = []\n",
    "            DAGs_dict[p][n_sample][a] = []\n",
    "            p_values_dict[p][n_sample][a] = []\n",
    "\n",
    "            # generate synthetic data\n",
    "            edges, X = generate_data(dep=test, n_samples=n_sample, n_trials=n_trials, n_obs=n_obs, n_preds=n_preds, period=p, n_vars=n_vars, a=a, upper_limit=upper_limit, n_basis=n_basis, sd=sd, prob=prob, linear=linear, log_sys=log_sys, analyse=analyse)\n",
    "            \n",
    "            # conduct n trials\n",
    "            precisions, recalls, f1_scores, SHDs, GLs, CPDAGs, p_values = causal_eval(cd_type=cd_type, X_dict=X, edges_dict=edges, upper_limit=upper_limit, n_preds=n_preds, n_intervals=n_intervals, n_trials=n_trials, n_perms=n_perms, alpha=alpha, K='K_ID', lambs=lambs, analyse=analyse)\n",
    "\n",
    "            precisions_dict[p][n_sample][a].append(precisions)\n",
    "            recalls_dict[p][n_sample][a].append(recalls)\n",
    "            f1_scores_dict[p][n_sample][a].append(f1_scores)\n",
    "            SHDs_dict[p][n_sample][a].append(SHDs)\n",
    "            GLs_dict[p][n_sample][a].append(GLs)\n",
    "\n",
    "            edges_dict[p][n_sample][a].append(edges)\n",
    "            DAGs_dict[p][n_sample][a].append(CPDAGs)\n",
    "            p_values_dict[p][n_sample][a].append(p_values)\n",
    "\n",
    "            # calculate average precision, recall and F1-score\n",
    "            avg_precision = np.mean(precisions_dict[p][n_sample][a])\n",
    "            avg_recall = np.mean(recalls_dict[p][n_sample][a])\n",
    "            avg_f1_score = np.mean(f1_scores_dict[p][n_sample][a])\n",
    "            avg_SHDs = np.mean(SHDs_dict[p][n_sample][a])\n",
    "            avg_GLs = np.mean(GLs_dict[p][n_sample][a])\n",
    "\n",
    "            averages_dict[p][n_sample][a].append([avg_precision, avg_recall, avg_f1_score, avg_SHDs, avg_GLs])\n",
    "\n",
    "            print('Average SHD:', avg_SHDs)\n",
    "            print('Average Precision:', avg_precision)\n",
    "            print('Average Recall:', avg_recall)\n",
    "            print('----------')\n",
    "        print('----------')\n",
    "    print('----------')\n",
    "\n",
    "precision_causal = open('results/causal/precision_{}_{}.pkl'.format(cd_type, n_vars), 'wb')\n",
    "pickle.dump(precisions_dict, precision_causal)\n",
    "precision_causal.close()\n",
    "recall_causal = open('results/causal/recall_{}_{}.pkl'.format(cd_type, n_vars), 'wb')\n",
    "pickle.dump(recalls_dict, recall_causal)\n",
    "recall_causal.close()\n",
    "f1_causal = open('results/causal/f1_{}_{}.pkl'.format(cd_type, n_vars), 'wb')\n",
    "pickle.dump(f1_scores_dict, f1_causal)\n",
    "f1_causal.close()\n",
    "SHD_causal = open('results/causal/shd_{}_{}.pkl'.format(cd_type, n_vars), 'wb')\n",
    "pickle.dump(SHDs_dict, SHD_causal)\n",
    "SHD_causal.close()\n",
    "GL_causal = open('results/causal/GL_{}_{}.pkl'.format(cd_type, n_vars), 'wb')\n",
    "pickle.dump(GLs_dict, GL_causal)\n",
    "GL_causal.close()\n",
    "averages_causal = open('results/causal/averages_{}_{}.pkl'.format(cd_type, n_vars), 'wb')\n",
    "pickle.dump(averages_dict, averages_causal)\n",
    "averages_causal.close()\n",
    "\n",
    "edges_causal = open('results/causal/edges_{}_{}.pkl'.format(cd_type, n_vars), 'wb')\n",
    "pickle.dump(edges_dict, edges_causal)\n",
    "edges_causal.close()\n",
    "DAGs_causal = open('results/causal/DAGs_{}_{}.pkl'.format(cd_type, n_vars), 'wb')\n",
    "pickle.dump(DAGs_dict, DAGs_causal)\n",
    "DAGs_causal.close()\n",
    "pvalues_causal = open('results/causal/p_values_{}_{}.pkl'.format(cd_type, n_vars), 'wb')\n",
    "pickle.dump(p_values_dict, pvalues_causal)\n",
    "pvalues_causal.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}